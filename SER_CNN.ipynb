{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SER_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3VJvD5O/sI0pi/R/pB9or",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aluvala-nikhil/SER/blob/main/SER_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sap5smqPewxO"
      },
      "source": [
        "Mounting Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXLj9s46IODD",
        "outputId": "a2397cff-9374-4526-ee2d-8149875f4b7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkLvolU4e1hQ"
      },
      "source": [
        "Installing Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7QWUE7pYEpw"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPBj3ofVdOlI"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjcoKaiWfUSZ"
      },
      "source": [
        "Installing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNgpUCJsdRW7"
      },
      "source": [
        "!pip install python_speech_features\n",
        "!pip install resampy\n",
        "!pip install scipy\n",
        "!pip install gdown\n",
        "!pip install tqdm -U\n",
        "!pip install soundfile\n",
        "!pip install noisereduce\n",
        "!pip install wave\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio\n",
        "!pip install python_speech_features\n",
        "!pip install wavio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ckC2GJfaHv"
      },
      "source": [
        "Importing requried libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94B8t8rodtdS"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from python_speech_features import mfcc , logfbank\n",
        "import librosa as lr\n",
        "import os, glob, pickle\n",
        "import librosa\n",
        "from scipy import signal\n",
        "import noisereduce as nr\n",
        "from glob import glob\n",
        "import librosa\n",
        "get_ipython().magic('matplotlib inline')\n",
        "import soundfile\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D, Flatten, LSTM\n",
        "from keras.layers import Dropout,Dense,TimeDistributed\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical \n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMKcSeLzffKB"
      },
      "source": [
        "Appending the dataset to a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PosZbrUudzij"
      },
      "source": [
        "os.listdir(path='/content/drive/MyDrive/Speech123/')\n",
        "def getListOfFiles(dirName):\n",
        "    listOfFile=os.listdir(dirName)\n",
        "    allFiles=list()\n",
        "    for entry in listOfFile:\n",
        "        fullPath=os.path.join(dirName, entry)\n",
        "        if os.path.isdir(fullPath):\n",
        "            allFiles=allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)\n",
        "    return allFiles\n",
        " \n",
        "dirName = '/content/drive/MyDrive/Speech123/'\n",
        "listOfFiles = getListOfFiles(dirName)\n",
        "len(listOfFiles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3lPTUVmfkPa"
      },
      "source": [
        "Installing librosa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdfOoDFJIal_",
        "outputId": "91d45c8d-7294-4d53-b6b2-b2c42a69f80b"
      },
      "source": [
        "!pip install librosa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (56.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (20.9)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA-HviGXfnAK"
      },
      "source": [
        "Installind speech recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ348CJjd75X"
      },
      "source": [
        "!pip install SpeechRecognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYisnMgzfqfm"
      },
      "source": [
        "Speech to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EloIzBEsd8nV"
      },
      "source": [
        "import speech_recognition as sr\n",
        "r=sr.Recognizer()\n",
        "for file in range(0 , len(listOfFiles) , 1):\n",
        "    with sr.AudioFile(listOfFiles[file]) as source:\n",
        "        audio = r.listen(source)\n",
        "        try:\n",
        "            text = r.recognize_google(audio)\n",
        "            print(text)\n",
        "        except:\n",
        "            print('error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOBIuZAMfs5G"
      },
      "source": [
        "Plotting time graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-qtT3sWeBbB"
      },
      "source": [
        "\n",
        "#Plotting the Basic Graphs for understanding of Audio Files :\n",
        "for file in range(0 , len(listOfFiles) , 1):\n",
        "    audio , sfreq = lr.load(listOfFiles[file])\n",
        "    time = np.arange(0 , len(audio)) / sfreq\n",
        "    fig ,ax = plt.subplots()\n",
        "    ax.plot(time , audio)\n",
        "    ax.set(xlabel = 'Time (s)' , ylabel = 'Sound Amplitude')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQyx5DZmfvm9"
      },
      "source": [
        "MLP classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LghYw4f-eQJo"
      },
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R29w5SkzeY7y"
      },
      "source": [
        "def extract_feature(file_name, mfcc, chroma, mel):\n",
        "    X, sample_rate = librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n",
        "    if chroma:\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "    result=np.array([])\n",
        "    if mfcc:\n",
        "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        result=np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, mel))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK6DvyIKea59"
      },
      "source": [
        "# Emotions in the RAVDESS & TESS dataset\n",
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "# Emotions to observe\n",
        "observed_emotions=['neutral','calm','happy','sad','angry','fearful', 'disgust','surprised']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZAgw6BYedMJ"
      },
      "source": [
        "def load_data(test_size=0.2):\n",
        "    x,y=[],[]\n",
        "    for file in glob.glob('/content/drive/MyDrive/Speech123/Actor*/*.wav'):\n",
        "        file_name=os.path.basename(file)\n",
        "        emotion=emotions[file_name.split(\"-\")[2]]\n",
        "        if emotion not in observed_emotions:\n",
        "            continue\n",
        "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        x.append(feature)\n",
        "        y.append(emotion)\n",
        "    return train_test_split(np.array(x), y, test_size=test_size, train_size= 0.75,random_state=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfpRaVtcefOs"
      },
      "source": [
        "import time\n",
        "x_train,x_test,y_train,y_test=load_data(test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxsW3U9rehGQ"
      },
      "source": [
        "print((x_train.shape[0], x_test.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgp-00MPei8u"
      },
      "source": [
        "print(f'Features extracted: {x_train.shape[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI_Xcd06eki7"
      },
      "source": [
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zupFV0wOenRX"
      },
      "source": [
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq6sHoPoerdf"
      },
      "source": [
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "# Print the accuracy\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM6xcJCvesTo"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9TAoDgmIeIe",
        "outputId": "24ec0757-e1ce-4164-a403-e3794dc733b3"
      },
      "source": [
        "import time\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "path = '/content/drive/MyDrive/Speech123/'\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfccs, store the file and the mfccs information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Data loaded. Loading time: 1379.7502818107605 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nWbzdnBIiCp"
      },
      "source": [
        "X, y = zip(*lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSmIUX-ZIkin",
        "outputId": "b8d1e1d7-6b96-43a6-a393-fad2670c2140"
      },
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2880, 40), (2880,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qgECKECImpT"
      },
      "source": [
        "import joblib\n",
        "\n",
        "X_name = 'X.joblib'\n",
        "y_name = 'y.joblib'\n",
        "save_dir = '/content/drive/MyDrive/Ravdess_model'\n",
        "\n",
        "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47zEllHHIqKQ"
      },
      "source": [
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/Ravdess_model/X.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/Ravdess_model/y.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwans_y1Isnx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EyDsd3mIusd",
        "outputId": "753091ea-6b89-4341-84ea-9be7372c3eab"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZdp7OkJIxPX"
      },
      "source": [
        "predictions = dtree.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10hYr_INIz8X",
        "outputId": "0ff86ea3-beb9-4c28-b593-5962fb11892f"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.68      0.73        68\n",
            "           1       0.84      0.80      0.82       142\n",
            "           2       0.75      0.85      0.80       108\n",
            "           3       0.90      0.80      0.85       132\n",
            "           4       0.78      0.91      0.84       127\n",
            "           5       0.74      0.82      0.78       112\n",
            "           6       0.75      0.79      0.77       136\n",
            "           7       0.88      0.71      0.79       126\n",
            "\n",
            "    accuracy                           0.80       951\n",
            "   macro avg       0.81      0.80      0.80       951\n",
            "weighted avg       0.81      0.80      0.80       951\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDUeODV8I2C-"
      },
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55hJ3tIuI5qM",
        "outputId": "ac070ba3-8a28-422b-a6e5-e68116f16f75"
      },
      "source": [
        "x_traincnn.shape, x_testcnn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1929, 40, 1), (951, 40, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cMUg4P2I-ze"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(64, 5,padding='same',\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(256, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(8))\n",
        "model.add(Activation('softmax'))\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.00005, rho=0.9, epsilon=1e-07)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dwlufzsJBZh",
        "outputId": "b85985d0-6146-45e3-a057-5c39f8e808a5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 40, 64)            384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 40, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 40, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 10, 128)           41088     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 2, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 2, 256)            164096    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 4104      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 209,672\n",
            "Trainable params: 209,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GoQV-jWJEpa"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVZzdsdxJHQF",
        "outputId": "fff62bf4-16d0-4e10-e428-fae0f9266504"
      },
      "source": [
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=300, validation_data=(x_testcnn, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "121/121 [==============================] - 2s 18ms/step - loss: 4.3095 - accuracy: 0.1291 - val_loss: 2.1065 - val_accuracy: 0.1851\n",
            "Epoch 2/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 3.5768 - accuracy: 0.1327 - val_loss: 2.0213 - val_accuracy: 0.2082\n",
            "Epoch 3/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 2.9780 - accuracy: 0.1659 - val_loss: 1.9382 - val_accuracy: 0.2566\n",
            "Epoch 4/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 2.6544 - accuracy: 0.1763 - val_loss: 2.1182 - val_accuracy: 0.1851\n",
            "Epoch 5/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 2.4333 - accuracy: 0.1903 - val_loss: 1.9258 - val_accuracy: 0.2303\n",
            "Epoch 6/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 2.3357 - accuracy: 0.1840 - val_loss: 1.8973 - val_accuracy: 0.2576\n",
            "Epoch 7/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 2.1459 - accuracy: 0.2188 - val_loss: 1.9584 - val_accuracy: 0.2187\n",
            "Epoch 8/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 2.1036 - accuracy: 0.2234 - val_loss: 1.8941 - val_accuracy: 0.2324\n",
            "Epoch 9/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 2.0780 - accuracy: 0.2364 - val_loss: 1.8638 - val_accuracy: 0.2881\n",
            "Epoch 10/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 2.0234 - accuracy: 0.2369 - val_loss: 1.9006 - val_accuracy: 0.3207\n",
            "Epoch 11/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 2.0099 - accuracy: 0.2328 - val_loss: 1.8437 - val_accuracy: 0.2955\n",
            "Epoch 12/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.9974 - accuracy: 0.2354 - val_loss: 1.8138 - val_accuracy: 0.3354\n",
            "Epoch 13/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.9469 - accuracy: 0.2545 - val_loss: 1.8219 - val_accuracy: 0.3249\n",
            "Epoch 14/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.9349 - accuracy: 0.2701 - val_loss: 1.7936 - val_accuracy: 0.3701\n",
            "Epoch 15/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.9085 - accuracy: 0.2649 - val_loss: 1.8178 - val_accuracy: 0.3113\n",
            "Epoch 16/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.8946 - accuracy: 0.2680 - val_loss: 1.7789 - val_accuracy: 0.3460\n",
            "Epoch 17/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.8940 - accuracy: 0.2748 - val_loss: 1.7728 - val_accuracy: 0.3575\n",
            "Epoch 18/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.8579 - accuracy: 0.2825 - val_loss: 1.7463 - val_accuracy: 0.3481\n",
            "Epoch 19/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.8618 - accuracy: 0.2908 - val_loss: 1.7814 - val_accuracy: 0.3344\n",
            "Epoch 20/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.8356 - accuracy: 0.2934 - val_loss: 1.7448 - val_accuracy: 0.3554\n",
            "Epoch 21/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.8504 - accuracy: 0.2950 - val_loss: 1.7510 - val_accuracy: 0.3302\n",
            "Epoch 22/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.8349 - accuracy: 0.2976 - val_loss: 1.7258 - val_accuracy: 0.3638\n",
            "Epoch 23/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.8195 - accuracy: 0.3043 - val_loss: 1.7278 - val_accuracy: 0.3775\n",
            "Epoch 24/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.8129 - accuracy: 0.3126 - val_loss: 1.6921 - val_accuracy: 0.3901\n",
            "Epoch 25/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.8023 - accuracy: 0.3204 - val_loss: 1.7122 - val_accuracy: 0.3733\n",
            "Epoch 26/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.7930 - accuracy: 0.3193 - val_loss: 1.6781 - val_accuracy: 0.4017\n",
            "Epoch 27/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.7582 - accuracy: 0.3313 - val_loss: 1.6652 - val_accuracy: 0.3985\n",
            "Epoch 28/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.7595 - accuracy: 0.3364 - val_loss: 1.6788 - val_accuracy: 0.3838\n",
            "Epoch 29/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.7516 - accuracy: 0.3390 - val_loss: 1.6589 - val_accuracy: 0.4122\n",
            "Epoch 30/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.7321 - accuracy: 0.3339 - val_loss: 1.6902 - val_accuracy: 0.3407\n",
            "Epoch 31/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.7496 - accuracy: 0.3224 - val_loss: 1.6382 - val_accuracy: 0.4080\n",
            "Epoch 32/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.7252 - accuracy: 0.3339 - val_loss: 1.6160 - val_accuracy: 0.4027\n",
            "Epoch 33/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.7238 - accuracy: 0.3458 - val_loss: 1.6477 - val_accuracy: 0.4017\n",
            "Epoch 34/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.6814 - accuracy: 0.3541 - val_loss: 1.6140 - val_accuracy: 0.4101\n",
            "Epoch 35/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.6872 - accuracy: 0.3644 - val_loss: 1.6188 - val_accuracy: 0.3933\n",
            "Epoch 36/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.6779 - accuracy: 0.3572 - val_loss: 1.5864 - val_accuracy: 0.4238\n",
            "Epoch 37/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.6789 - accuracy: 0.3598 - val_loss: 1.5748 - val_accuracy: 0.4385\n",
            "Epoch 38/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.6710 - accuracy: 0.3572 - val_loss: 1.6033 - val_accuracy: 0.4059\n",
            "Epoch 39/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.6525 - accuracy: 0.3774 - val_loss: 1.5554 - val_accuracy: 0.4458\n",
            "Epoch 40/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.6601 - accuracy: 0.3733 - val_loss: 1.5629 - val_accuracy: 0.4059\n",
            "Epoch 41/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.6571 - accuracy: 0.3691 - val_loss: 1.5578 - val_accuracy: 0.4206\n",
            "Epoch 42/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.6296 - accuracy: 0.3898 - val_loss: 1.5727 - val_accuracy: 0.4280\n",
            "Epoch 43/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.6098 - accuracy: 0.3961 - val_loss: 1.5514 - val_accuracy: 0.4238\n",
            "Epoch 44/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.6070 - accuracy: 0.3904 - val_loss: 1.5287 - val_accuracy: 0.4343\n",
            "Epoch 45/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.6084 - accuracy: 0.3857 - val_loss: 1.4991 - val_accuracy: 0.4532\n",
            "Epoch 46/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.6040 - accuracy: 0.3857 - val_loss: 1.5170 - val_accuracy: 0.4458\n",
            "Epoch 47/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.5963 - accuracy: 0.3904 - val_loss: 1.5286 - val_accuracy: 0.4427\n",
            "Epoch 48/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.5742 - accuracy: 0.3997 - val_loss: 1.5551 - val_accuracy: 0.4143\n",
            "Epoch 49/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.5842 - accuracy: 0.4007 - val_loss: 1.4840 - val_accuracy: 0.4522\n",
            "Epoch 50/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.5592 - accuracy: 0.4235 - val_loss: 1.4658 - val_accuracy: 0.4606\n",
            "Epoch 51/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.5737 - accuracy: 0.4090 - val_loss: 1.4595 - val_accuracy: 0.4763\n",
            "Epoch 52/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.5450 - accuracy: 0.4126 - val_loss: 1.4554 - val_accuracy: 0.4742\n",
            "Epoch 53/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.5306 - accuracy: 0.4168 - val_loss: 1.4459 - val_accuracy: 0.4711\n",
            "Epoch 54/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.5177 - accuracy: 0.4215 - val_loss: 1.4699 - val_accuracy: 0.4458\n",
            "Epoch 55/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.5249 - accuracy: 0.4422 - val_loss: 1.4277 - val_accuracy: 0.4742\n",
            "Epoch 56/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.5022 - accuracy: 0.4453 - val_loss: 1.4241 - val_accuracy: 0.4669\n",
            "Epoch 57/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.5006 - accuracy: 0.4277 - val_loss: 1.4071 - val_accuracy: 0.5016\n",
            "Epoch 58/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.4924 - accuracy: 0.4469 - val_loss: 1.4169 - val_accuracy: 0.4921\n",
            "Epoch 59/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.4745 - accuracy: 0.4417 - val_loss: 1.3954 - val_accuracy: 0.4879\n",
            "Epoch 60/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.4679 - accuracy: 0.4557 - val_loss: 1.4123 - val_accuracy: 0.4795\n",
            "Epoch 61/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.4568 - accuracy: 0.4495 - val_loss: 1.3641 - val_accuracy: 0.5068\n",
            "Epoch 62/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.4514 - accuracy: 0.4562 - val_loss: 1.3721 - val_accuracy: 0.5110\n",
            "Epoch 63/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.4543 - accuracy: 0.4484 - val_loss: 1.3687 - val_accuracy: 0.5100\n",
            "Epoch 64/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.4504 - accuracy: 0.4624 - val_loss: 1.3878 - val_accuracy: 0.5005\n",
            "Epoch 65/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.4294 - accuracy: 0.4619 - val_loss: 1.3670 - val_accuracy: 0.4942\n",
            "Epoch 66/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.4177 - accuracy: 0.4666 - val_loss: 1.3441 - val_accuracy: 0.5037\n",
            "Epoch 67/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.4128 - accuracy: 0.4645 - val_loss: 1.3604 - val_accuracy: 0.4837\n",
            "Epoch 68/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.4013 - accuracy: 0.4738 - val_loss: 1.3317 - val_accuracy: 0.4963\n",
            "Epoch 69/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.3966 - accuracy: 0.4738 - val_loss: 1.3196 - val_accuracy: 0.5352\n",
            "Epoch 70/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.3927 - accuracy: 0.4816 - val_loss: 1.3409 - val_accuracy: 0.5068\n",
            "Epoch 71/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.3806 - accuracy: 0.4894 - val_loss: 1.3181 - val_accuracy: 0.5121\n",
            "Epoch 72/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.3913 - accuracy: 0.4837 - val_loss: 1.2950 - val_accuracy: 0.5321\n",
            "Epoch 73/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.3689 - accuracy: 0.5044 - val_loss: 1.2975 - val_accuracy: 0.5342\n",
            "Epoch 74/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.3557 - accuracy: 0.5065 - val_loss: 1.3017 - val_accuracy: 0.5310\n",
            "Epoch 75/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.3578 - accuracy: 0.5008 - val_loss: 1.2939 - val_accuracy: 0.5163\n",
            "Epoch 76/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.3459 - accuracy: 0.4961 - val_loss: 1.2734 - val_accuracy: 0.5394\n",
            "Epoch 77/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.3102 - accuracy: 0.5246 - val_loss: 1.3097 - val_accuracy: 0.5195\n",
            "Epoch 78/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.3301 - accuracy: 0.5174 - val_loss: 1.2847 - val_accuracy: 0.5100\n",
            "Epoch 79/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.3298 - accuracy: 0.5013 - val_loss: 1.2583 - val_accuracy: 0.5426\n",
            "Epoch 80/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.3059 - accuracy: 0.5236 - val_loss: 1.2425 - val_accuracy: 0.5426\n",
            "Epoch 81/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 1.3029 - accuracy: 0.5210 - val_loss: 1.2654 - val_accuracy: 0.5363\n",
            "Epoch 82/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.3000 - accuracy: 0.5194 - val_loss: 1.2505 - val_accuracy: 0.5352\n",
            "Epoch 83/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.2932 - accuracy: 0.5210 - val_loss: 1.2296 - val_accuracy: 0.5794\n",
            "Epoch 84/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.2715 - accuracy: 0.5397 - val_loss: 1.2349 - val_accuracy: 0.5415\n",
            "Epoch 85/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.2725 - accuracy: 0.5241 - val_loss: 1.2140 - val_accuracy: 0.5521\n",
            "Epoch 86/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.2472 - accuracy: 0.5438 - val_loss: 1.2233 - val_accuracy: 0.5226\n",
            "Epoch 87/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.2621 - accuracy: 0.5412 - val_loss: 1.1920 - val_accuracy: 0.5699\n",
            "Epoch 88/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.2323 - accuracy: 0.5391 - val_loss: 1.2005 - val_accuracy: 0.5668\n",
            "Epoch 89/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.2360 - accuracy: 0.5557 - val_loss: 1.1918 - val_accuracy: 0.5731\n",
            "Epoch 90/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.2311 - accuracy: 0.5578 - val_loss: 1.1711 - val_accuracy: 0.5868\n",
            "Epoch 91/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.2334 - accuracy: 0.5469 - val_loss: 1.1968 - val_accuracy: 0.5825\n",
            "Epoch 92/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.2270 - accuracy: 0.5562 - val_loss: 1.1841 - val_accuracy: 0.5668\n",
            "Epoch 93/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.2246 - accuracy: 0.5599 - val_loss: 1.1703 - val_accuracy: 0.5973\n",
            "Epoch 94/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.2087 - accuracy: 0.5573 - val_loss: 1.1724 - val_accuracy: 0.5857\n",
            "Epoch 95/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.2196 - accuracy: 0.5583 - val_loss: 1.2028 - val_accuracy: 0.5563\n",
            "Epoch 96/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1930 - accuracy: 0.5562 - val_loss: 1.2145 - val_accuracy: 0.5426\n",
            "Epoch 97/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.1680 - accuracy: 0.5702 - val_loss: 1.1543 - val_accuracy: 0.5920\n",
            "Epoch 98/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1789 - accuracy: 0.5666 - val_loss: 1.1360 - val_accuracy: 0.6025\n",
            "Epoch 99/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1920 - accuracy: 0.5754 - val_loss: 1.1646 - val_accuracy: 0.5594\n",
            "Epoch 100/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1564 - accuracy: 0.5759 - val_loss: 1.1912 - val_accuracy: 0.5731\n",
            "Epoch 101/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1542 - accuracy: 0.5625 - val_loss: 1.1273 - val_accuracy: 0.6067\n",
            "Epoch 102/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1418 - accuracy: 0.5625 - val_loss: 1.1456 - val_accuracy: 0.5699\n",
            "Epoch 103/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1497 - accuracy: 0.5837 - val_loss: 1.1491 - val_accuracy: 0.5899\n",
            "Epoch 104/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1483 - accuracy: 0.5863 - val_loss: 1.1535 - val_accuracy: 0.5710\n",
            "Epoch 105/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1453 - accuracy: 0.5910 - val_loss: 1.1149 - val_accuracy: 0.5920\n",
            "Epoch 106/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1398 - accuracy: 0.5837 - val_loss: 1.1374 - val_accuracy: 0.5857\n",
            "Epoch 107/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1304 - accuracy: 0.5998 - val_loss: 1.1180 - val_accuracy: 0.6120\n",
            "Epoch 108/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 1.1208 - accuracy: 0.5863 - val_loss: 1.0891 - val_accuracy: 0.6236\n",
            "Epoch 109/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1259 - accuracy: 0.5874 - val_loss: 1.0826 - val_accuracy: 0.6183\n",
            "Epoch 110/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.1312 - accuracy: 0.5884 - val_loss: 1.0677 - val_accuracy: 0.6477\n",
            "Epoch 111/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0951 - accuracy: 0.6091 - val_loss: 1.1100 - val_accuracy: 0.5868\n",
            "Epoch 112/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0741 - accuracy: 0.6086 - val_loss: 1.1155 - val_accuracy: 0.5910\n",
            "Epoch 113/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0930 - accuracy: 0.6003 - val_loss: 1.0858 - val_accuracy: 0.6078\n",
            "Epoch 114/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0589 - accuracy: 0.6128 - val_loss: 1.0743 - val_accuracy: 0.6141\n",
            "Epoch 115/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0822 - accuracy: 0.5993 - val_loss: 1.0670 - val_accuracy: 0.6078\n",
            "Epoch 116/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0773 - accuracy: 0.6185 - val_loss: 1.0528 - val_accuracy: 0.6330\n",
            "Epoch 117/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0727 - accuracy: 0.6039 - val_loss: 1.0495 - val_accuracy: 0.6278\n",
            "Epoch 118/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0582 - accuracy: 0.6153 - val_loss: 1.0468 - val_accuracy: 0.6330\n",
            "Epoch 119/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0446 - accuracy: 0.6247 - val_loss: 1.0660 - val_accuracy: 0.6120\n",
            "Epoch 120/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0493 - accuracy: 0.6195 - val_loss: 1.0434 - val_accuracy: 0.6309\n",
            "Epoch 121/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0430 - accuracy: 0.6174 - val_loss: 1.0222 - val_accuracy: 0.6404\n",
            "Epoch 122/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0271 - accuracy: 0.6319 - val_loss: 1.0366 - val_accuracy: 0.6540\n",
            "Epoch 123/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0230 - accuracy: 0.6335 - val_loss: 1.0483 - val_accuracy: 0.6215\n",
            "Epoch 124/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0325 - accuracy: 0.6309 - val_loss: 1.0688 - val_accuracy: 0.6278\n",
            "Epoch 125/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0226 - accuracy: 0.6309 - val_loss: 1.0483 - val_accuracy: 0.6215\n",
            "Epoch 126/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0016 - accuracy: 0.6366 - val_loss: 1.0040 - val_accuracy: 0.6488\n",
            "Epoch 127/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0019 - accuracy: 0.6397 - val_loss: 1.0428 - val_accuracy: 0.6215\n",
            "Epoch 128/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9872 - accuracy: 0.6542 - val_loss: 1.0102 - val_accuracy: 0.6446\n",
            "Epoch 129/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0029 - accuracy: 0.6335 - val_loss: 1.0098 - val_accuracy: 0.6362\n",
            "Epoch 130/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 1.0052 - accuracy: 0.6345 - val_loss: 1.0006 - val_accuracy: 0.6635\n",
            "Epoch 131/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9706 - accuracy: 0.6563 - val_loss: 1.0130 - val_accuracy: 0.6456\n",
            "Epoch 132/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9731 - accuracy: 0.6376 - val_loss: 0.9953 - val_accuracy: 0.6509\n",
            "Epoch 133/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9810 - accuracy: 0.6449 - val_loss: 1.0047 - val_accuracy: 0.6435\n",
            "Epoch 134/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9717 - accuracy: 0.6532 - val_loss: 0.9708 - val_accuracy: 0.6698\n",
            "Epoch 135/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9649 - accuracy: 0.6542 - val_loss: 0.9648 - val_accuracy: 0.6740\n",
            "Epoch 136/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9560 - accuracy: 0.6475 - val_loss: 0.9768 - val_accuracy: 0.6761\n",
            "Epoch 137/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9414 - accuracy: 0.6630 - val_loss: 0.9638 - val_accuracy: 0.6614\n",
            "Epoch 138/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9374 - accuracy: 0.6625 - val_loss: 0.9537 - val_accuracy: 0.6730\n",
            "Epoch 139/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.9361 - accuracy: 0.6610 - val_loss: 0.9391 - val_accuracy: 0.6835\n",
            "Epoch 140/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9088 - accuracy: 0.6776 - val_loss: 0.9849 - val_accuracy: 0.6583\n",
            "Epoch 141/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9162 - accuracy: 0.6620 - val_loss: 0.9309 - val_accuracy: 0.6856\n",
            "Epoch 142/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9271 - accuracy: 0.6527 - val_loss: 0.9427 - val_accuracy: 0.6772\n",
            "Epoch 143/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9230 - accuracy: 0.6661 - val_loss: 0.9779 - val_accuracy: 0.6225\n",
            "Epoch 144/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.9151 - accuracy: 0.6599 - val_loss: 0.9317 - val_accuracy: 0.6993\n",
            "Epoch 145/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9084 - accuracy: 0.6853 - val_loss: 0.9283 - val_accuracy: 0.6835\n",
            "Epoch 146/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8924 - accuracy: 0.6791 - val_loss: 0.9329 - val_accuracy: 0.6698\n",
            "Epoch 147/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8953 - accuracy: 0.6713 - val_loss: 0.9190 - val_accuracy: 0.7056\n",
            "Epoch 148/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.8896 - accuracy: 0.6884 - val_loss: 0.9106 - val_accuracy: 0.6972\n",
            "Epoch 149/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8632 - accuracy: 0.6900 - val_loss: 0.9681 - val_accuracy: 0.6562\n",
            "Epoch 150/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.9061 - accuracy: 0.6744 - val_loss: 0.9253 - val_accuracy: 0.7024\n",
            "Epoch 151/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8940 - accuracy: 0.6734 - val_loss: 0.9181 - val_accuracy: 0.7014\n",
            "Epoch 152/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8625 - accuracy: 0.6770 - val_loss: 0.9188 - val_accuracy: 0.6740\n",
            "Epoch 153/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.8643 - accuracy: 0.6843 - val_loss: 0.9228 - val_accuracy: 0.6635\n",
            "Epoch 154/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8515 - accuracy: 0.6879 - val_loss: 0.9197 - val_accuracy: 0.6972\n",
            "Epoch 155/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8670 - accuracy: 0.6827 - val_loss: 0.9261 - val_accuracy: 0.6898\n",
            "Epoch 156/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8541 - accuracy: 0.6895 - val_loss: 0.9151 - val_accuracy: 0.6772\n",
            "Epoch 157/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8500 - accuracy: 0.6957 - val_loss: 0.8852 - val_accuracy: 0.7098\n",
            "Epoch 158/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8314 - accuracy: 0.7009 - val_loss: 0.9206 - val_accuracy: 0.6940\n",
            "Epoch 159/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8401 - accuracy: 0.6910 - val_loss: 0.8686 - val_accuracy: 0.7087\n",
            "Epoch 160/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.8254 - accuracy: 0.6941 - val_loss: 0.8965 - val_accuracy: 0.6919\n",
            "Epoch 161/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8373 - accuracy: 0.6952 - val_loss: 0.8998 - val_accuracy: 0.6993\n",
            "Epoch 162/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8141 - accuracy: 0.7185 - val_loss: 0.8625 - val_accuracy: 0.7119\n",
            "Epoch 163/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8275 - accuracy: 0.7035 - val_loss: 0.8588 - val_accuracy: 0.7150\n",
            "Epoch 164/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8288 - accuracy: 0.7118 - val_loss: 0.8554 - val_accuracy: 0.7308\n",
            "Epoch 165/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.8144 - accuracy: 0.7097 - val_loss: 0.8906 - val_accuracy: 0.7056\n",
            "Epoch 166/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7874 - accuracy: 0.7252 - val_loss: 0.8500 - val_accuracy: 0.7287\n",
            "Epoch 167/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.7760 - accuracy: 0.7263 - val_loss: 0.8419 - val_accuracy: 0.7203\n",
            "Epoch 168/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.8108 - accuracy: 0.6952 - val_loss: 0.8453 - val_accuracy: 0.7319\n",
            "Epoch 169/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7701 - accuracy: 0.7263 - val_loss: 0.8634 - val_accuracy: 0.7098\n",
            "Epoch 170/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.7969 - accuracy: 0.7133 - val_loss: 0.8570 - val_accuracy: 0.7203\n",
            "Epoch 171/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7788 - accuracy: 0.7087 - val_loss: 0.8535 - val_accuracy: 0.7213\n",
            "Epoch 172/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7700 - accuracy: 0.7221 - val_loss: 0.8944 - val_accuracy: 0.7077\n",
            "Epoch 173/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7782 - accuracy: 0.7128 - val_loss: 0.8520 - val_accuracy: 0.7108\n",
            "Epoch 174/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7887 - accuracy: 0.7107 - val_loss: 0.8252 - val_accuracy: 0.7256\n",
            "Epoch 175/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7593 - accuracy: 0.7315 - val_loss: 0.8182 - val_accuracy: 0.7213\n",
            "Epoch 176/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7546 - accuracy: 0.7387 - val_loss: 0.8162 - val_accuracy: 0.7350\n",
            "Epoch 177/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7626 - accuracy: 0.7195 - val_loss: 0.8604 - val_accuracy: 0.7066\n",
            "Epoch 178/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7690 - accuracy: 0.7180 - val_loss: 0.8369 - val_accuracy: 0.7066\n",
            "Epoch 179/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.7516 - accuracy: 0.7273 - val_loss: 0.8431 - val_accuracy: 0.6982\n",
            "Epoch 180/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.7358 - accuracy: 0.7320 - val_loss: 0.8224 - val_accuracy: 0.7298\n",
            "Epoch 181/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7464 - accuracy: 0.7320 - val_loss: 0.8376 - val_accuracy: 0.7245\n",
            "Epoch 182/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7390 - accuracy: 0.7242 - val_loss: 0.7935 - val_accuracy: 0.7350\n",
            "Epoch 183/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7381 - accuracy: 0.7232 - val_loss: 0.7915 - val_accuracy: 0.7424\n",
            "Epoch 184/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.7194 - accuracy: 0.7434 - val_loss: 0.8103 - val_accuracy: 0.7403\n",
            "Epoch 185/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.7244 - accuracy: 0.7356 - val_loss: 0.7975 - val_accuracy: 0.7340\n",
            "Epoch 186/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.7256 - accuracy: 0.7372 - val_loss: 0.8144 - val_accuracy: 0.7287\n",
            "Epoch 187/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.7258 - accuracy: 0.7506 - val_loss: 0.7929 - val_accuracy: 0.7371\n",
            "Epoch 188/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.7066 - accuracy: 0.7470 - val_loss: 0.7711 - val_accuracy: 0.7529\n",
            "Epoch 189/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6993 - accuracy: 0.7589 - val_loss: 0.8284 - val_accuracy: 0.7140\n",
            "Epoch 190/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6989 - accuracy: 0.7491 - val_loss: 0.7742 - val_accuracy: 0.7466\n",
            "Epoch 191/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6977 - accuracy: 0.7543 - val_loss: 0.7663 - val_accuracy: 0.7508\n",
            "Epoch 192/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6945 - accuracy: 0.7496 - val_loss: 0.7735 - val_accuracy: 0.7487\n",
            "Epoch 193/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6984 - accuracy: 0.7470 - val_loss: 0.8069 - val_accuracy: 0.7392\n",
            "Epoch 194/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6606 - accuracy: 0.7652 - val_loss: 0.7746 - val_accuracy: 0.7382\n",
            "Epoch 195/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6798 - accuracy: 0.7626 - val_loss: 0.7644 - val_accuracy: 0.7340\n",
            "Epoch 196/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6575 - accuracy: 0.7693 - val_loss: 0.7655 - val_accuracy: 0.7350\n",
            "Epoch 197/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6936 - accuracy: 0.7548 - val_loss: 0.7602 - val_accuracy: 0.7424\n",
            "Epoch 198/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6874 - accuracy: 0.7667 - val_loss: 0.7589 - val_accuracy: 0.7592\n",
            "Epoch 199/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6770 - accuracy: 0.7724 - val_loss: 0.7620 - val_accuracy: 0.7434\n",
            "Epoch 200/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6770 - accuracy: 0.7646 - val_loss: 0.7540 - val_accuracy: 0.7560\n",
            "Epoch 201/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6324 - accuracy: 0.7911 - val_loss: 0.7752 - val_accuracy: 0.7361\n",
            "Epoch 202/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6781 - accuracy: 0.7703 - val_loss: 0.7460 - val_accuracy: 0.7655\n",
            "Epoch 203/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6477 - accuracy: 0.7703 - val_loss: 0.7305 - val_accuracy: 0.7560\n",
            "Epoch 204/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6358 - accuracy: 0.7740 - val_loss: 0.7757 - val_accuracy: 0.7424\n",
            "Epoch 205/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6434 - accuracy: 0.7760 - val_loss: 0.7278 - val_accuracy: 0.7697\n",
            "Epoch 206/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6275 - accuracy: 0.7828 - val_loss: 0.7383 - val_accuracy: 0.7613\n",
            "Epoch 207/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6185 - accuracy: 0.7880 - val_loss: 0.7685 - val_accuracy: 0.7350\n",
            "Epoch 208/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6547 - accuracy: 0.7652 - val_loss: 0.7785 - val_accuracy: 0.7371\n",
            "Epoch 209/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6277 - accuracy: 0.7724 - val_loss: 0.7176 - val_accuracy: 0.7697\n",
            "Epoch 210/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6025 - accuracy: 0.7947 - val_loss: 0.7322 - val_accuracy: 0.7508\n",
            "Epoch 211/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6351 - accuracy: 0.7807 - val_loss: 0.7416 - val_accuracy: 0.7603\n",
            "Epoch 212/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6128 - accuracy: 0.7869 - val_loss: 0.7274 - val_accuracy: 0.7624\n",
            "Epoch 213/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.6192 - accuracy: 0.7833 - val_loss: 0.6967 - val_accuracy: 0.7813\n",
            "Epoch 214/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6207 - accuracy: 0.7729 - val_loss: 0.7422 - val_accuracy: 0.7613\n",
            "Epoch 215/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5950 - accuracy: 0.7957 - val_loss: 0.6968 - val_accuracy: 0.7729\n",
            "Epoch 216/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.6021 - accuracy: 0.7957 - val_loss: 0.7108 - val_accuracy: 0.7655\n",
            "Epoch 217/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5822 - accuracy: 0.8035 - val_loss: 0.6810 - val_accuracy: 0.7865\n",
            "Epoch 218/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5961 - accuracy: 0.7921 - val_loss: 0.6960 - val_accuracy: 0.7592\n",
            "Epoch 219/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.5856 - accuracy: 0.7968 - val_loss: 0.6851 - val_accuracy: 0.7718\n",
            "Epoch 220/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.5999 - accuracy: 0.7963 - val_loss: 0.6866 - val_accuracy: 0.7792\n",
            "Epoch 221/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.5826 - accuracy: 0.7963 - val_loss: 0.7281 - val_accuracy: 0.7497\n",
            "Epoch 222/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.5784 - accuracy: 0.7890 - val_loss: 0.6868 - val_accuracy: 0.7802\n",
            "Epoch 223/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5766 - accuracy: 0.7895 - val_loss: 0.6863 - val_accuracy: 0.7771\n",
            "Epoch 224/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5884 - accuracy: 0.7983 - val_loss: 0.6782 - val_accuracy: 0.7802\n",
            "Epoch 225/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.5652 - accuracy: 0.7983 - val_loss: 0.6728 - val_accuracy: 0.7813\n",
            "Epoch 226/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5727 - accuracy: 0.8015 - val_loss: 0.6554 - val_accuracy: 0.7823\n",
            "Epoch 227/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5759 - accuracy: 0.7895 - val_loss: 0.6890 - val_accuracy: 0.7823\n",
            "Epoch 228/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5432 - accuracy: 0.8035 - val_loss: 0.6846 - val_accuracy: 0.7792\n",
            "Epoch 229/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5664 - accuracy: 0.7968 - val_loss: 0.6689 - val_accuracy: 0.7844\n",
            "Epoch 230/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5396 - accuracy: 0.8258 - val_loss: 0.6747 - val_accuracy: 0.7897\n",
            "Epoch 231/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5690 - accuracy: 0.7983 - val_loss: 0.6646 - val_accuracy: 0.7823\n",
            "Epoch 232/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.5402 - accuracy: 0.8108 - val_loss: 0.6620 - val_accuracy: 0.7897\n",
            "Epoch 233/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5348 - accuracy: 0.8170 - val_loss: 0.6454 - val_accuracy: 0.7865\n",
            "Epoch 234/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5264 - accuracy: 0.8196 - val_loss: 0.6541 - val_accuracy: 0.7813\n",
            "Epoch 235/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5321 - accuracy: 0.8201 - val_loss: 0.6443 - val_accuracy: 0.7960\n",
            "Epoch 236/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5399 - accuracy: 0.8092 - val_loss: 0.6521 - val_accuracy: 0.7907\n",
            "Epoch 237/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5296 - accuracy: 0.8061 - val_loss: 0.6461 - val_accuracy: 0.7876\n",
            "Epoch 238/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.5471 - accuracy: 0.8035 - val_loss: 0.6357 - val_accuracy: 0.7939\n",
            "Epoch 239/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5287 - accuracy: 0.8222 - val_loss: 0.6339 - val_accuracy: 0.7928\n",
            "Epoch 240/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5354 - accuracy: 0.8087 - val_loss: 0.7047 - val_accuracy: 0.7560\n",
            "Epoch 241/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5266 - accuracy: 0.8165 - val_loss: 0.6584 - val_accuracy: 0.7928\n",
            "Epoch 242/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5075 - accuracy: 0.8289 - val_loss: 0.6388 - val_accuracy: 0.7960\n",
            "Epoch 243/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5133 - accuracy: 0.8227 - val_loss: 0.6254 - val_accuracy: 0.7918\n",
            "Epoch 244/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5249 - accuracy: 0.8237 - val_loss: 0.6261 - val_accuracy: 0.7928\n",
            "Epoch 245/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5095 - accuracy: 0.8206 - val_loss: 0.6340 - val_accuracy: 0.7939\n",
            "Epoch 246/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5259 - accuracy: 0.8129 - val_loss: 0.6124 - val_accuracy: 0.8055\n",
            "Epoch 247/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5094 - accuracy: 0.8284 - val_loss: 0.6473 - val_accuracy: 0.8097\n",
            "Epoch 248/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5018 - accuracy: 0.8377 - val_loss: 0.6390 - val_accuracy: 0.8118\n",
            "Epoch 249/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5057 - accuracy: 0.8284 - val_loss: 0.6556 - val_accuracy: 0.7844\n",
            "Epoch 250/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4908 - accuracy: 0.8372 - val_loss: 0.6319 - val_accuracy: 0.7992\n",
            "Epoch 251/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4979 - accuracy: 0.8269 - val_loss: 0.6137 - val_accuracy: 0.8034\n",
            "Epoch 252/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4738 - accuracy: 0.8388 - val_loss: 0.6270 - val_accuracy: 0.7939\n",
            "Epoch 253/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5092 - accuracy: 0.8248 - val_loss: 0.6054 - val_accuracy: 0.8118\n",
            "Epoch 254/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.4835 - accuracy: 0.8367 - val_loss: 0.6447 - val_accuracy: 0.8013\n",
            "Epoch 255/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.5047 - accuracy: 0.8201 - val_loss: 0.6203 - val_accuracy: 0.8097\n",
            "Epoch 256/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.4782 - accuracy: 0.8367 - val_loss: 0.6240 - val_accuracy: 0.8023\n",
            "Epoch 257/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.4635 - accuracy: 0.8450 - val_loss: 0.6196 - val_accuracy: 0.8013\n",
            "Epoch 258/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4692 - accuracy: 0.8357 - val_loss: 0.5866 - val_accuracy: 0.8107\n",
            "Epoch 259/300\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.4603 - accuracy: 0.8414 - val_loss: 0.6035 - val_accuracy: 0.8013\n",
            "Epoch 260/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4841 - accuracy: 0.8419 - val_loss: 0.5911 - val_accuracy: 0.8191\n",
            "Epoch 261/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4718 - accuracy: 0.8429 - val_loss: 0.5860 - val_accuracy: 0.8286\n",
            "Epoch 262/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4587 - accuracy: 0.8455 - val_loss: 0.6144 - val_accuracy: 0.8149\n",
            "Epoch 263/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4667 - accuracy: 0.8388 - val_loss: 0.5781 - val_accuracy: 0.8139\n",
            "Epoch 264/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4417 - accuracy: 0.8517 - val_loss: 0.5885 - val_accuracy: 0.8212\n",
            "Epoch 265/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4585 - accuracy: 0.8471 - val_loss: 0.5682 - val_accuracy: 0.8160\n",
            "Epoch 266/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4543 - accuracy: 0.8424 - val_loss: 0.5556 - val_accuracy: 0.8191\n",
            "Epoch 267/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4509 - accuracy: 0.8414 - val_loss: 0.5606 - val_accuracy: 0.8181\n",
            "Epoch 268/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4158 - accuracy: 0.8626 - val_loss: 0.5490 - val_accuracy: 0.8170\n",
            "Epoch 269/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4432 - accuracy: 0.8497 - val_loss: 0.5660 - val_accuracy: 0.8223\n",
            "Epoch 270/300\n",
            "121/121 [==============================] - 2s 18ms/step - loss: 0.4465 - accuracy: 0.8517 - val_loss: 0.5755 - val_accuracy: 0.8223\n",
            "Epoch 271/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4453 - accuracy: 0.8569 - val_loss: 0.5489 - val_accuracy: 0.8286\n",
            "Epoch 272/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4226 - accuracy: 0.8585 - val_loss: 0.5657 - val_accuracy: 0.8202\n",
            "Epoch 273/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4277 - accuracy: 0.8445 - val_loss: 0.5653 - val_accuracy: 0.8381\n",
            "Epoch 274/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4323 - accuracy: 0.8466 - val_loss: 0.5630 - val_accuracy: 0.8128\n",
            "Epoch 275/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4112 - accuracy: 0.8631 - val_loss: 0.5720 - val_accuracy: 0.8181\n",
            "Epoch 276/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4374 - accuracy: 0.8523 - val_loss: 0.5395 - val_accuracy: 0.8318\n",
            "Epoch 277/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4089 - accuracy: 0.8663 - val_loss: 0.5560 - val_accuracy: 0.8191\n",
            "Epoch 278/300\n",
            "121/121 [==============================] - 2s 18ms/step - loss: 0.4229 - accuracy: 0.8574 - val_loss: 0.5514 - val_accuracy: 0.8297\n",
            "Epoch 279/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4317 - accuracy: 0.8564 - val_loss: 0.5723 - val_accuracy: 0.8160\n",
            "Epoch 280/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4129 - accuracy: 0.8642 - val_loss: 0.5493 - val_accuracy: 0.8212\n",
            "Epoch 281/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4187 - accuracy: 0.8569 - val_loss: 0.5732 - val_accuracy: 0.8097\n",
            "Epoch 282/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4370 - accuracy: 0.8538 - val_loss: 0.5386 - val_accuracy: 0.8318\n",
            "Epoch 283/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3986 - accuracy: 0.8652 - val_loss: 0.5810 - val_accuracy: 0.7960\n",
            "Epoch 284/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4127 - accuracy: 0.8580 - val_loss: 0.5397 - val_accuracy: 0.8212\n",
            "Epoch 285/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4070 - accuracy: 0.8605 - val_loss: 0.5397 - val_accuracy: 0.8233\n",
            "Epoch 286/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4137 - accuracy: 0.8631 - val_loss: 0.5251 - val_accuracy: 0.8381\n",
            "Epoch 287/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3991 - accuracy: 0.8678 - val_loss: 0.5206 - val_accuracy: 0.8254\n",
            "Epoch 288/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3962 - accuracy: 0.8709 - val_loss: 0.5193 - val_accuracy: 0.8391\n",
            "Epoch 289/300\n",
            "121/121 [==============================] - 2s 18ms/step - loss: 0.4001 - accuracy: 0.8663 - val_loss: 0.5627 - val_accuracy: 0.8170\n",
            "Epoch 290/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3959 - accuracy: 0.8569 - val_loss: 0.5313 - val_accuracy: 0.8265\n",
            "Epoch 291/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.4025 - accuracy: 0.8559 - val_loss: 0.5360 - val_accuracy: 0.8286\n",
            "Epoch 292/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3803 - accuracy: 0.8694 - val_loss: 0.5194 - val_accuracy: 0.8402\n",
            "Epoch 293/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3938 - accuracy: 0.8631 - val_loss: 0.5129 - val_accuracy: 0.8454\n",
            "Epoch 294/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3779 - accuracy: 0.8673 - val_loss: 0.5347 - val_accuracy: 0.8328\n",
            "Epoch 295/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3694 - accuracy: 0.8730 - val_loss: 0.5274 - val_accuracy: 0.8307\n",
            "Epoch 296/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3710 - accuracy: 0.8730 - val_loss: 0.5125 - val_accuracy: 0.8423\n",
            "Epoch 297/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3710 - accuracy: 0.8668 - val_loss: 0.5432 - val_accuracy: 0.8202\n",
            "Epoch 298/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3782 - accuracy: 0.8751 - val_loss: 0.5351 - val_accuracy: 0.8381\n",
            "Epoch 299/300\n",
            "121/121 [==============================] - 2s 18ms/step - loss: 0.3743 - accuracy: 0.8714 - val_loss: 0.5137 - val_accuracy: 0.8360\n",
            "Epoch 300/300\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.3853 - accuracy: 0.8699 - val_loss: 0.5256 - val_accuracy: 0.8328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "W2TzWh94JL25",
        "outputId": "7f204485-1599-4aca-c147-079baefebd7a"
      },
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "EeowbJSVJUKg",
        "outputId": "7a09a0d3-50cc-4b4e-e92c-b8f232248f58"
      },
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaudGegqJU5K",
        "outputId": "ae5afd3b-d7ea-435d-c14b-2955ac83b41f"
      },
      "source": [
        "predictions = model.predict_classes(x_testcnn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEmheaIsJgWh"
      },
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8pmjZBgJksZ",
        "outputId": "606871e6-4454-417c-e65f-fc6934633586"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(new_Ytest, predictions)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.40      0.56        68\n",
            "           1       0.83      0.97      0.90       142\n",
            "           2       0.81      0.89      0.85       108\n",
            "           3       0.80      0.78      0.79       132\n",
            "           4       0.79      0.91      0.85       127\n",
            "           5       0.86      0.88      0.87       112\n",
            "           6       0.83      0.80      0.82       136\n",
            "           7       0.89      0.83      0.86       126\n",
            "\n",
            "    accuracy                           0.83       951\n",
            "   macro avg       0.85      0.81      0.81       951\n",
            "weighted avg       0.84      0.83      0.83       951\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZYZZNVFJnum",
        "outputId": "36709ded-ecf3-4b89-aa51-bc70d837312e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(new_Ytest, predictions)\n",
        "print (matrix)\n",
        "\n",
        "# 0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 27  17   1  15   1   0   7   0]\n",
            " [  1 138   0   3   0   0   0   0]\n",
            " [  0   0  96   4   5   1   0   2]\n",
            " [  0   4   5 103   5  10   2   3]\n",
            " [  0   1   1   0 116   2   5   2]\n",
            " [  0   0   9   2   2  98   1   0]\n",
            " [  0   4   0   2  12   3 109   6]\n",
            " [  0   2   6   0   6   0   7 105]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dq5l0n4JqRT",
        "outputId": "7fe9fc85-7406-4735-cbb8-37f8785ec23b"
      },
      "source": [
        "model.save('testing_model.h5')\n",
        "print(\"MODEL SAVED\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL SAVED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "IVqZ3e9_JsjZ",
        "outputId": "5d38555f-c927-44ea-feb1-8afd3e8debcb"
      },
      "source": [
        "new_model=keras.models.load_model('/content/testing01_model.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-d5ca39aaee7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/testing01_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/testing01_model.h5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PItj7njbJu_M",
        "outputId": "47b42ea3-2e3f-449f-a896-37110234c226"
      },
      "source": [
        "loss, acc = new_model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.8275\n",
            "Restored model, accuracy: 82.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBJDMcq9JySa",
        "outputId": "3bcd6d58-7bcc-4819-c9d2-52c70df79f6e"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "This file can be used to try a live prediction. \n",
        "\"\"\"\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "class livePredictions:\n",
        "    \"\"\"\n",
        "    Main class of the application.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path, file):\n",
        "        \"\"\"\n",
        "        Init method is used to initialize the main parameters.\n",
        "        \"\"\"\n",
        "        self.path = path\n",
        "        self.file = file\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"\n",
        "        Method to load the chosen model.\n",
        "        :param path: path to your h5 model.\n",
        "        :return: summary of the model with the .summary() function.\n",
        "        \"\"\"\n",
        "        self.loaded_model = keras.models.load_model(self.path)\n",
        "        return self.loaded_model.summary()\n",
        "\n",
        "    def makepredictions(self):\n",
        "        \"\"\"\n",
        "        Method to process the files and create your features.\n",
        "        \"\"\"\n",
        "        data, sampling_rate = librosa.load(self.file)\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
        "        x = np.expand_dims(mfccs, axis=1)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        predictions = self.loaded_model.predict_classes(x)\n",
        "        print(\"Prediction is\", \" \", self.convertclasstoemotion(predictions))\n",
        "\n",
        "    @staticmethod\n",
        "    def convertclasstoemotion(pred):\n",
        "        \"\"\"\n",
        "        Method to convert the predictions (int) into human readable strings.\n",
        "        \"\"\"\n",
        "        \n",
        "        label_conversion = {'0': 'neutral',\n",
        "                            '1': 'calm',\n",
        "                            '2': 'happy',\n",
        "                            '3': 'sad',\n",
        "                            '4': 'angry',\n",
        "                            '5': 'fearful',\n",
        "                            '6': 'disgust',\n",
        "                            '7': 'surprised'}\n",
        "\n",
        "        for key, value in label_conversion.items():\n",
        "            if int(key) == pred:\n",
        "                label = value\n",
        "        return label\n",
        "\n",
        "# Here you can replace path and file with the path of your model and of the file \n",
        "#from the RAVDESS dataset you want to use for the prediction,\n",
        "\n",
        "pred = livePredictions(path='/content/drive/MyDrive/testing01_model.h5',file='/content/drive/MyDrive/SpeechEmotionReco/2021-04-30T06_48_17.698Z.wav')\n",
        "\n",
        "pred.load_model()\n",
        "pred.makepredictions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 40, 64)            384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 40, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 40, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 10, 128)           41088     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 2, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 2, 256)            164096    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 4104      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 209,672\n",
            "Trainable params: 209,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f39fc4555f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Prediction is   calm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}